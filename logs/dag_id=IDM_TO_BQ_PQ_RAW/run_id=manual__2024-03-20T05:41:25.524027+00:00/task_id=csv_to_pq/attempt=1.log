[2024-03-20T05:46:12.305+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: IDM_TO_BQ_PQ_RAW.csv_to_pq manual__2024-03-20T05:41:25.524027+00:00 [queued]>
[2024-03-20T05:46:12.309+0000] {taskinstance.py:1979} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: IDM_TO_BQ_PQ_RAW.csv_to_pq manual__2024-03-20T05:41:25.524027+00:00 [queued]>
[2024-03-20T05:46:12.309+0000] {taskinstance.py:2193} INFO - Starting attempt 1 of 1
[2024-03-20T05:46:12.314+0000] {taskinstance.py:2217} INFO - Executing <Task(BashOperator): csv_to_pq> on 2024-03-20 05:41:25.524027+00:00
[2024-03-20T05:46:12.316+0000] {standard_task_runner.py:60} INFO - Started process 4285 to run task
[2024-03-20T05:46:12.317+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'IDM_TO_BQ_PQ_RAW', 'csv_to_pq', 'manual__2024-03-20T05:41:25.524027+00:00', '--job-id', '34', '--raw', '--subdir', 'DAGS_FOLDER/IDM_TO_BQ_PQ_RAW.py', '--cfg-path', '/tmp/tmpdtxb12g7']
[2024-03-20T05:46:12.319+0000] {standard_task_runner.py:88} INFO - Job 34: Subtask csv_to_pq
[2024-03-20T05:46:12.327+0000] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.8/site-packages/***/settings.py:194 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2024-03-20T05:46:12.340+0000] {task_command.py:423} INFO - Running <TaskInstance: IDM_TO_BQ_PQ_RAW.csv_to_pq manual__2024-03-20T05:41:25.524027+00:00 [running]> on host bf143d508a6e
[2024-03-20T05:46:12.374+0000] {taskinstance.py:2513} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='admin' AIRFLOW_CTX_DAG_ID='IDM_TO_BQ_PQ_RAW' AIRFLOW_CTX_TASK_ID='csv_to_pq' AIRFLOW_CTX_EXECUTION_DATE='2024-03-20T05:41:25.524027+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-03-20T05:41:25.524027+00:00'
[2024-03-20T05:46:12.375+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2024-03-20T05:46:12.376+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', "#!/bin/bash\n\nSERVICE_ACCOUNT_FILE_NAME=$GOOGLE_APPLICATION_CREDENTIALS\nPYTHON_DIR=/opt/***/src/idm_to_bq_pq_raw/pyspark/\nPYTHON_FILE=csv_to_pq.py\nDATAPROC_CLUSTER=dez-cluster\nDATAPROC_REGION=us-central1\nGCP_PROJECT=dez-workspace-emil\n\necho\necho 'SETTING UP SERVICE ACCOUNT'\ngcloud auth activate-service-account --key-file=$SERVICE_ACCOUNT_FILE_NAME\ngcloud config set project $GCP_PROJECT\n\necho\necho 'STARTING FROM CSV TO PARQUET'\n\ngcloud dataproc jobs submit pyspark $PYTHON_DIR$PYTHON_FILE --cluster=$DATAPROC_CLUSTER --region=$DATAPROC_REGION\n\necho\necho 'DONE!'"]
[2024-03-20T05:46:12.380+0000] {subprocess.py:86} INFO - Output:
[2024-03-20T05:46:12.381+0000] {subprocess.py:93} INFO - 
[2024-03-20T05:46:12.381+0000] {subprocess.py:93} INFO - SETTING UP SERVICE ACCOUNT
[2024-03-20T05:46:13.077+0000] {subprocess.py:93} INFO - Activated service account credentials for: [dez-project-emil@dez-workspace-emil.iam.gserviceaccount.com]
[2024-03-20T05:46:13.722+0000] {subprocess.py:93} INFO - WARNING: You do not appear to have access to project [dez-workspace-emil] or it does not exist.
[2024-03-20T05:46:13.724+0000] {subprocess.py:93} INFO - Updated property [core/project].
[2024-03-20T05:46:13.809+0000] {subprocess.py:93} INFO - 
[2024-03-20T05:46:13.810+0000] {subprocess.py:93} INFO - STARTING FROM CSV TO PARQUET
[2024-03-20T05:46:15.266+0000] {subprocess.py:93} INFO - Job [381d3f7cbb0f4d639884c19cfabb5630] submitted.
[2024-03-20T05:46:15.267+0000] {subprocess.py:93} INFO - Waiting for job output...
[2024-03-20T05:46:29.444+0000] {subprocess.py:93} INFO - 24/03/20 05:46:26 INFO SparkEnv: Registering MapOutputTracker
[2024-03-20T05:46:29.446+0000] {subprocess.py:93} INFO - 24/03/20 05:46:26 INFO SparkEnv: Registering BlockManagerMaster
[2024-03-20T05:46:29.447+0000] {subprocess.py:93} INFO - 24/03/20 05:46:26 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2024-03-20T05:46:29.448+0000] {subprocess.py:93} INFO - 24/03/20 05:46:27 INFO SparkEnv: Registering OutputCommitCoordinator
[2024-03-20T05:46:31.214+0000] {subprocess.py:93} INFO - 24/03/20 05:46:29 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at dez-cluster-m.us-central1-b.c.dez-workspace-emil.internal./10.128.0.6:8032
[2024-03-20T05:46:31.219+0000] {subprocess.py:93} INFO - 24/03/20 05:46:29 INFO AHSProxy: Connecting to Application History server at dez-cluster-m.us-central1-b.c.dez-workspace-emil.internal./10.128.0.6:10200
[2024-03-20T05:46:34.990+0000] {subprocess.py:93} INFO - 24/03/20 05:46:32 INFO Configuration: resource-types.xml not found
[2024-03-20T05:46:34.995+0000] {subprocess.py:93} INFO - 24/03/20 05:46:32 INFO ResourceUtils: Unable to find 'resource-types.xml'.
[2024-03-20T05:46:37.302+0000] {subprocess.py:93} INFO - 24/03/20 05:46:34 INFO YarnClientImpl: Submitted application application_1710913474836_0001
[2024-03-20T05:46:37.304+0000] {subprocess.py:93} INFO - 24/03/20 05:46:35 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at dez-cluster-m.us-central1-b.c.dez-workspace-emil.internal./10.128.0.6:8030
[2024-03-20T05:46:41.442+0000] {subprocess.py:93} INFO - 24/03/20 05:46:39 INFO GhfsStorageStatistics: Detected potential high latency for operation op_get_file_status. latencyMs=371; previousMaxLatencyMs=0; operationCount=1; context=gs://dataproc-temp-us-central1-329749248489-tvazyaju/830261e5-2d3d-4491-a80c-fd201b1ad541/spark-job-history
[2024-03-20T05:46:41.443+0000] {subprocess.py:93} INFO - 24/03/20 05:46:39 INFO GoogleCloudStorageImpl: Ignoring exception of type GoogleJsonResponseException; verified object already exists with desired state.
[2024-03-20T05:46:41.444+0000] {subprocess.py:93} INFO - 24/03/20 05:46:39 INFO GhfsStorageStatistics: Detected potential high latency for operation op_mkdirs. latencyMs=245; previousMaxLatencyMs=0; operationCount=1; context=gs://dataproc-temp-us-central1-329749248489-tvazyaju/830261e5-2d3d-4491-a80c-fd201b1ad541/spark-job-history
[2024-03-20T05:46:41.445+0000] {subprocess.py:93} INFO - 24/03/20 05:46:40 INFO GhfsStorageStatistics: Detected potential high latency for operation op_create. latencyMs=157; previousMaxLatencyMs=0; operationCount=1; context=gs://dataproc-temp-us-central1-329749248489-tvazyaju/830261e5-2d3d-4491-a80c-fd201b1ad541/spark-job-history/application_1710913474836_0001.inprogress
[2024-03-20T05:46:43.899+0000] {subprocess.py:93} INFO - READING CSV FILE
[2024-03-20T05:46:50.413+0000] {subprocess.py:93} INFO - TRANSFORMING DATA
[2024-03-20T05:46:53.156+0000] {subprocess.py:93} INFO - WRITING DATA
[2024-03-20T05:46:54.914+0000] {subprocess.py:93} INFO - 24/03/20 05:46:52 INFO GhfsStorageStatistics: Detected potential high latency for operation op_delete. latencyMs=415; previousMaxLatencyMs=0; operationCount=1; context=gs://landing_bucket_dez/pq/idm
[2024-03-20T05:48:19.345+0000] {subprocess.py:93} INFO - 24/03/20 05:48:17 INFO GoogleCloudStorageFileSystem: Successfully repaired 'gs://landing_bucket_dez/pq/idm/' directory.
[2024-03-20T05:48:19.351+0000] {subprocess.py:93} INFO - 24/03/20 05:48:17 INFO GhfsStorageStatistics: Detected potential high latency for operation op_delete. latencyMs=480; previousMaxLatencyMs=415; operationCount=2; context=gs://landing_bucket_dez/pq/idm/_temporary
[2024-03-20T05:48:21.443+0000] {subprocess.py:93} INFO - 24/03/20 05:48:18 INFO GhfsStorageStatistics: Detected potential high latency for operation stream_write_close_operations. latencyMs=252; previousMaxLatencyMs=0; operationCount=1; context=gs://landing_bucket_dez/pq/idm/_SUCCESS
[2024-03-20T05:48:21.444+0000] {subprocess.py:93} INFO - DONE!
[2024-03-20T05:48:23.314+0000] {subprocess.py:93} INFO - Job [381d3f7cbb0f4d639884c19cfabb5630] finished successfully.
[2024-03-20T05:48:23.343+0000] {subprocess.py:93} INFO - done: true
[2024-03-20T05:48:23.344+0000] {subprocess.py:93} INFO - driverControlFilesUri: gs://dataproc-staging-us-central1-329749248489-jq1oe9c7/google-cloud-dataproc-metainfo/830261e5-2d3d-4491-a80c-fd201b1ad541/jobs/381d3f7cbb0f4d639884c19cfabb5630/
[2024-03-20T05:48:23.345+0000] {subprocess.py:93} INFO - driverOutputResourceUri: gs://dataproc-staging-us-central1-329749248489-jq1oe9c7/google-cloud-dataproc-metainfo/830261e5-2d3d-4491-a80c-fd201b1ad541/jobs/381d3f7cbb0f4d639884c19cfabb5630/driveroutput
[2024-03-20T05:48:23.345+0000] {subprocess.py:93} INFO - jobUuid: a2ffec87-6e44-351b-983d-097f32b7abc7
[2024-03-20T05:48:23.346+0000] {subprocess.py:93} INFO - placement:
[2024-03-20T05:48:23.346+0000] {subprocess.py:93} INFO -   clusterName: dez-cluster
[2024-03-20T05:48:23.346+0000] {subprocess.py:93} INFO -   clusterUuid: 830261e5-2d3d-4491-a80c-fd201b1ad541
[2024-03-20T05:48:23.347+0000] {subprocess.py:93} INFO - pysparkJob:
[2024-03-20T05:48:23.347+0000] {subprocess.py:93} INFO -   mainPythonFileUri: gs://dataproc-staging-us-central1-329749248489-jq1oe9c7/google-cloud-dataproc-metainfo/830261e5-2d3d-4491-a80c-fd201b1ad541/jobs/381d3f7cbb0f4d639884c19cfabb5630/staging/csv_to_pq.py
[2024-03-20T05:48:23.347+0000] {subprocess.py:93} INFO - reference:
[2024-03-20T05:48:23.348+0000] {subprocess.py:93} INFO -   jobId: 381d3f7cbb0f4d639884c19cfabb5630
[2024-03-20T05:48:23.348+0000] {subprocess.py:93} INFO -   projectId: dez-workspace-emil
[2024-03-20T05:48:23.348+0000] {subprocess.py:93} INFO - status:
[2024-03-20T05:48:23.349+0000] {subprocess.py:93} INFO -   state: DONE
[2024-03-20T05:48:23.349+0000] {subprocess.py:93} INFO -   stateStartTime: '2024-03-20T05:48:22.009574Z'
[2024-03-20T05:48:23.349+0000] {subprocess.py:93} INFO - statusHistory:
[2024-03-20T05:48:23.350+0000] {subprocess.py:93} INFO - - state: PENDING
[2024-03-20T05:48:23.350+0000] {subprocess.py:93} INFO -   stateStartTime: '2024-03-20T05:46:15.245706Z'
[2024-03-20T05:48:23.351+0000] {subprocess.py:93} INFO - - state: SETUP_DONE
[2024-03-20T05:48:23.351+0000] {subprocess.py:93} INFO -   stateStartTime: '2024-03-20T05:46:15.278614Z'
[2024-03-20T05:48:23.351+0000] {subprocess.py:93} INFO - - details: Agent reported job success
[2024-03-20T05:48:23.352+0000] {subprocess.py:93} INFO -   state: RUNNING
[2024-03-20T05:48:23.352+0000] {subprocess.py:93} INFO -   stateStartTime: '2024-03-20T05:46:15.618593Z'
[2024-03-20T05:48:23.353+0000] {subprocess.py:93} INFO - yarnApplications:
[2024-03-20T05:48:23.353+0000] {subprocess.py:93} INFO - - name: test
[2024-03-20T05:48:23.353+0000] {subprocess.py:93} INFO -   progress: 1.0
[2024-03-20T05:48:23.354+0000] {subprocess.py:93} INFO -   state: FINISHED
[2024-03-20T05:48:23.354+0000] {subprocess.py:93} INFO -   trackingUrl: http://dez-cluster-m.us-central1-b.c.dez-workspace-emil.internal.:8088/proxy/application_1710913474836_0001/
[2024-03-20T05:48:23.440+0000] {subprocess.py:93} INFO - 
[2024-03-20T05:48:23.440+0000] {subprocess.py:93} INFO - DONE!
[2024-03-20T05:48:23.441+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2024-03-20T05:48:23.459+0000] {taskinstance.py:1149} INFO - Marking task as SUCCESS. dag_id=IDM_TO_BQ_PQ_RAW, task_id=csv_to_pq, execution_date=20240320T054125, start_date=20240320T054612, end_date=20240320T054823
[2024-03-20T05:48:23.474+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2024-03-20T05:48:23.490+0000] {taskinstance.py:3312} INFO - 1 downstream tasks scheduled from follow-on schedule check
